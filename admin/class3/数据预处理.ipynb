{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"./dataSet2.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 这是什么意思？\n",
    "# 读取csv文件\n",
    "# q: 读取出来的数据是什么格式？\n",
    "# a: dataframe是一个二维的表格\n",
    "df=pd.read_csv(\"./1.csv\")\n",
    "df\n",
    "# a: 读取第一行的数据\n",
    "# a: 保留6位小数 最多6位\n",
    "print(round(df[\"H3MeK4_N\"],5))\n",
    "# a: iloc[2] 是取第三行的数据\n",
    "print(df.iloc[2])\n",
    "# a: iloc是根据索引来取数据\n",
    "data=pd.DataFrame(df)\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[\"H3MeK4_N\"]) \n",
    "print(data.info()) \n",
    "print(data[\"CaNA_N\"].mean()) \n",
    "print(data[\"CaNA_N\"].var()) \n",
    "print(data[\"CaNA_N\"].median()) \n",
    "print(data.iloc[361])\n",
    "index1=[] \n",
    "for i in range (len(data[\"CaNA_N\"])): \n",
    "    #print(data.iloc[i][\"CaNA_N\"]) \n",
    "    if(data.iloc[i][\"CaNA_N\"]>2 or data.iloc[i][\"CaNA_N\"]<0.2):\n",
    "        index1.append(i)\n",
    "print(index1)\n",
    "data.drop(index1,inplace=True)\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    " \n",
    "data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#实现归一化\n",
    "scaler = MinMaxScaler()                             #实例化\n",
    "scaler = scaler.fit(data)                           #fit，在这里本质是生成min(x)和max(x)\n",
    "result = scaler.transform(data)                     #通过接口导出结果\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ = scaler.fit_transform(data)                #训练和导出结果一步达成\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.inverse_transform(result)                    #将归一化后的结果逆转"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用MinMaxScaler的参数feature_range实现将数据归一化到[0,1]以外的范围中\n",
    " \n",
    "data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
    "scaler = MinMaxScaler(feature_range=(5,10))         #依然实例化\n",
    "result = scaler.fit_transform(data)                 #fit_transform一步导出结果\n",
    "result\n",
    " \n",
    "#当X中的特征数量非常多的时候，fit会报错并表示，数据量太大了我计算不了\n",
    "#此时使用partial_fit作为训练接口\n",
    "#scaler = scaler.partial_fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = scaler.partial_fit(data)\n",
    "result = scaler.fit_transform(data)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array([[-1, 2], [-0.5, 6], [0, 10], [1, 18]])\n",
    " \n",
    "#归一化\n",
    "#print(X.min(axis=0),X.min())\n",
    "X_nor = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "X_nor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#逆转归一化\n",
    "X_returned = X_nor * (X.max(axis=0) - X.min(axis=0)) + X.min(axis=0)\n",
    "X_returned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler,MaxAbsScaler\n",
    "x = np.array([[3., -1., 2., 613.],\n",
    "              [2., 0., 0., 50],\n",
    "              [0., 1., -1., -113],\n",
    "              [1., 2., -3., 6]])\n",
    "\n",
    "# 定义放缩对象\n",
    "robust_scaler = RobustScaler(with_centering=True, with_scaling=True, quantile_range=(25.0, 75.0), copy=True)\n",
    "\n",
    "# 开始放缩\n",
    "x_robust = robust_scaler.fit_transform(x)\n",
    "\n",
    "# 打印放缩后的结果\n",
    "print(x_robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.array([[3., -1., 2., 613.],\n",
    "              [2., 0., 0., 5],\n",
    "              [0., 1., -1., -113],\n",
    "              [1., 2., -3., 6]])\n",
    "\n",
    "# 定义放缩对象\n",
    "MaxAbs_scaler = MaxAbsScaler()\n",
    "\n",
    "# 开始放缩\n",
    "x_MaxAbs = MaxAbs_scaler.fit_transform(x)\n",
    "\n",
    "# 打印放缩后的结果\n",
    "print(x_MaxAbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
    " \n",
    "scaler = StandardScaler()                           #实例化\n",
    "scaler.fit(data)                                    #fit，本质是生成均值和方差\n",
    " \n",
    "print(scaler.mean_)                                       #查看均值的属性mean_\n",
    "print(scaler.var_)                                         #查看方差的属性var_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_std = scaler.transform(data)                      #通过接口导出结果\n",
    " \n",
    "print(x_std.mean())                                        #导出的结果是一个数组，用mean()查看均值\n",
    "print(x_std.std())                                         #用std()查看方差\n",
    " \n",
    "print(scaler.fit_transform(data))                          #使用fit_transform(data)一步达成结果\n",
    " \n",
    "scaler.inverse_transform(x_std)                     #使用inverse_transform逆转标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(r\"Narrativedata.csv\"\n",
    "                   ,index_col=0\n",
    "                  )#index_col=0将第0列作为索引，不写则认为第0列为特征\n",
    " \n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()\n",
    "#填补年龄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Age = data.loc[:,\"Age\"].values.reshape(-1,1)            #sklearn当中特征矩阵必须是二维\n",
    "print(Age.shape)\n",
    "Age[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imp_mean = SimpleImputer()                              #实例化，默认均值填补\n",
    "imp_median = SimpleImputer(strategy=\"median\")           #用中位数填补\n",
    "imp_0 = SimpleImputer(strategy=\"constant\",fill_value=0) #用0填补\n",
    " \n",
    "imp_mean = imp_mean.fit_transform(Age)                  #fit_transform一步完成调取结果\n",
    "imp_median = imp_median.fit_transform(Age)\n",
    "imp_0 = imp_0.fit_transform(Age)\n",
    " \n",
    "print(imp_mean[:20])\n",
    "print(imp_median[:20])\n",
    "print(imp_0[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在这里我们使用中位数填补Age\n",
    "data.loc[:,\"Age\"] = imp_median\n",
    " \n",
    "data.info()\n",
    " \n",
    "#使用众数填补Embarked\n",
    "Embarked = data.loc[:,\"Embarked\"].values.reshape(-1,1)\n",
    "imp_mode = SimpleImputer(strategy = \"most_frequent\")\n",
    "data.loc[:,\"Embarked\"] = imp_mode.fit_transform(Embarked)\n",
    " \n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_ = pd.read_csv(r\"Narrativedata.csv\"\n",
    "                   ,index_col=0\n",
    "                  )#index_col=0将第0列作为索引，不写则认为第0列为特征\n",
    "\n",
    "data_.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_.loc[:,\"Age\"] = data_.loc[:,\"Age\"].fillna(data_.loc[:,\"Age\"].median())\n",
    "#.fillna 在DataFrame里面直接进行填补"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_.dropna(axis=0,inplace=True)\n",
    "#.dropna(axis=0)删除所有有缺失值的行，.dropna(axis=1)删除所有有缺失值的列\n",
    "#参数inplace，为True表示在原数据集上进行修改，为False表示生成一个复制对象，不修改原数据，默认False\n",
    "# _data_ = data_.drop(axis=0,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    " \n",
    "y = data_.iloc[:,-1]                         #要输入的是标签，不是特征矩阵，所以允许一维\n",
    " \n",
    "le = LabelEncoder()                         #实例化\n",
    "le = le.fit(y)                              #导入数据\n",
    "label = le.transform(y)                     #transform接口调取结果\n",
    " \n",
    "print(le.classes_)                                 #属性.classes_查看标签中究竟有多少类别\n",
    "print(label)                                       #查看获取的结果label\n",
    " \n",
    "le.fit_transform(y)                         #也可以直接fit_transform一步到位\n",
    " \n",
    "le.inverse_transform(label)                 #使用inverse_transform可以逆转"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    " \n",
    "y = data.iloc[:,-1]                         #要输入的是标签，不是特征矩阵，所以允许一维\n",
    " \n",
    "le = LabelEncoder()                         #实例化\n",
    "le = le.fit(y)                              #导入数据\n",
    "label = le.transform(y)                     #transform接口调取结果\n",
    " \n",
    "print(le.classes_)                                 #属性.classes_查看标签中究竟有多少类别\n",
    "print(label)                                       #查看获取的结果label\n",
    " \n",
    "le.fit_transform(y)                         #也可以直接fit_transform一步到位\n",
    " \n",
    "le.inverse_transform(label)                 #使用inverse_transform可以逆转\n",
    "\n",
    "data.iloc[:,-1] = label                     #让标签等于我们运行出来的结果\n",
    " \n",
    "print(data.head())\n",
    " \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "data.iloc[:,-1] = LabelEncoder().fit_transform(data.iloc[:,-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    " \n",
    "#接口categories_对应LabelEncoder的接口classes_，一模一样的功能\n",
    "data_ = data_.copy()\n",
    " \n",
    "data_.head()\n",
    " \n",
    "OrdinalEncoder().fit(data_.iloc[:,1:-1]).categories_\n",
    " \n",
    "data_.iloc[:,1:-1] = OrdinalEncoder().fit_transform(data_.iloc[:,1:-1])\n",
    " \n",
    "data_.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_.head())\n",
    " \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "X = data_.iloc[:,1:-1]\n",
    "print(X)\n",
    "enc = OneHotEncoder(categories='auto').fit(X)\n",
    "result = enc.transform(X).toarray()\n",
    "print(result)\n",
    " \n",
    "#依然可以直接一步到位，但为了给大家展示模型属性，所以还是写成了三步\n",
    "OneHotEncoder(categories='auto').fit_transform(X).toarray()\n",
    " \n",
    "#依然可以还原\n",
    "pd.DataFrame(enc.inverse_transform(result))\n",
    " \n",
    "enc.get_feature_names_out()#返回每一个经过哑变量后生成稀疏矩阵列的名字\n",
    " \n",
    "print(result)\n",
    "print(result.shape)\n",
    " \n",
    "#axis=1,表示跨行进行合并，也就是将两表左右相连，如果是axis=0，就是将量表上下相连\n",
    "newdata = pd.concat([data_,pd.DataFrame(result)],axis=1)\n",
    " \n",
    "newdata.head()\n",
    " \n",
    "newdata.drop([\"Sex\",\"Embarked\"],axis=1,inplace=True)\n",
    " \n",
    "newdata.columns = [\"Age\",\"Survived\",\"Female\",\"Male\",\"Embarked_C\",\"Embarked_Q\",\"Embarked_S\"]\n",
    " \n",
    "newdata.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将年龄二值化\n",
    " \n",
    "data_2 = data_.copy()\n",
    " \n",
    "from sklearn.preprocessing import Binarizer\n",
    "X = data_2.iloc[:,0].values.reshape(-1,1)               #类为特征专用，所以不能使用一维数组\n",
    "transformer = Binarizer(threshold=30).fit_transform(X)\n",
    " \n",
    "data_2.iloc[:,0] = transformer\n",
    "data_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "print(data_)\n",
    "X = data_.iloc[:,0].values.reshape(-1,1)\n",
    "#print(X)\n",
    "est = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "#uniform’：每个特征中的所有 bin 具有相同的宽度。\n",
    "#‘quantile’：每个特征中的所有 bin 具有相同数量的点。\n",
    "#‘kmeans’：每个 bin 中的值具有相同的一维 k-means 簇的最近中心。\n",
    "print(est.fit_transform(X))\n",
    " \n",
    "#查看转换后分的箱：变成了一列中的三箱\n",
    "set(est.fit_transform(X).ravel())\n",
    " \n",
    "est = KBinsDiscretizer(n_bins=3, encode='onehot', strategy='uniform')\n",
    "#查看转换后分的箱：变成了哑变量\n",
    "est.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
